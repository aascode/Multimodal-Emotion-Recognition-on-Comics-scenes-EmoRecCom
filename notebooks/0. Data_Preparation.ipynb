{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from pandas_profiling import ProfileReport"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_df = pd.read_csv('../data/public_train/train_emotion_labels.csv',header=None,names=['id','image_id','Angry'\\\n",
    "                                                                                                    ,'Disgust','Fear','Happy','Sad',\\\n",
    "                                                                                                    'Surprise','Neutral','Others'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>image_id</th>\n",
       "      <th>Angry</th>\n",
       "      <th>Disgust</th>\n",
       "      <th>Fear</th>\n",
       "      <th>Happy</th>\n",
       "      <th>Sad</th>\n",
       "      <th>Surprise</th>\n",
       "      <th>Neutral</th>\n",
       "      <th>Others</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>image_id</td>\n",
       "      <td>angry</td>\n",
       "      <td>disgust</td>\n",
       "      <td>fear</td>\n",
       "      <td>happy</td>\n",
       "      <td>sad</td>\n",
       "      <td>surprise</td>\n",
       "      <td>neutral</td>\n",
       "      <td>other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0_19_3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0_21_4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0_3_4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0_35_3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6108</td>\n",
       "      <td>6107.0</td>\n",
       "      <td>3829_15_3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6109</td>\n",
       "      <td>6108.0</td>\n",
       "      <td>3259_15_4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6110</td>\n",
       "      <td>6109.0</td>\n",
       "      <td>929_19_0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6111</td>\n",
       "      <td>6110.0</td>\n",
       "      <td>2945_30_1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6112</td>\n",
       "      <td>6111.0</td>\n",
       "      <td>330_37_0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6113 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id   image_id  Angry  Disgust  Fear  Happy  Sad  Surprise  Neutral  \\\n",
       "0        NaN   image_id  angry  disgust  fear  happy  sad  surprise  neutral   \n",
       "1        0.0     0_19_3      0        0     1      0    0         1        1   \n",
       "2        1.0     0_21_4      1        0     1      1    0         0        1   \n",
       "3        2.0      0_3_4      0        0     0      1    0         0        1   \n",
       "4        3.0     0_35_3      0        0     0      1    1         0        1   \n",
       "...      ...        ...    ...      ...   ...    ...  ...       ...      ...   \n",
       "6108  6107.0  3829_15_3      1        0     1      0    0         0        0   \n",
       "6109  6108.0  3259_15_4      1        1     0      0    0         0        0   \n",
       "6110  6109.0   929_19_0      1        0     0      1    0         0        1   \n",
       "6111  6110.0  2945_30_1      0        0     1      0    0         1        1   \n",
       "6112  6111.0   330_37_0      0        0     0      1    0         0        1   \n",
       "\n",
       "     Others  \n",
       "0     other  \n",
       "1         0  \n",
       "2         0  \n",
       "3         0  \n",
       "4         0  \n",
       "...     ...  \n",
       "6108      0  \n",
       "6109      0  \n",
       "6110      0  \n",
       "6111      1  \n",
       "6112      0  \n",
       "\n",
       "[6113 rows x 10 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['image_id', '0_19_3', '0_21_4', ..., '929_19_0', '2945_30_1',\n",
       "       '330_37_0'], dtype=object)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_df.image_id.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        3682\n",
       "1        2430\n",
       "angry       1\n",
       "Name: Angry, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_df.Angry.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0          3899\n",
       "1          2213\n",
       "disgust       1\n",
       "Name: Disgust, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_df.Disgust.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       3992\n",
       "1       2120\n",
       "fear       1\n",
       "Name: Fear, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_df.Fear.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        3588\n",
       "1        2524\n",
       "happy       1\n",
       "Name: Happy, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_df.Happy.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      5180\n",
       "1       932\n",
       "sad       1\n",
       "Name: Sad, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_df.Sad.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0           4013\n",
       "1           2099\n",
       "surprise       1\n",
       "Name: Surprise, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_df.Surprise.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1          4133\n",
       "0          1979\n",
       "neutral       1\n",
       "Name: Neutral, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_df.Neutral.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        5692\n",
       "1         420\n",
       "other       1\n",
       "Name: Others, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_df.Others.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6113"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(label_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transcription_df = pd.read_json('../data/public_train/train_transcriptions.json')\n",
    "with open('../data/public_train/train_transcriptions.json') as file:\n",
    "    train_transcripts = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "transcription_df = pd.DataFrame(train_transcripts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dialog</th>\n",
       "      <th>narration</th>\n",
       "      <th>img_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>[ the chief mentioned that the place was deser...</td>\n",
       "      <td>[]</td>\n",
       "      <td>0_19_3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>[disappoint you but id probably give you]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0_21_4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>[ah i feel better already now for a brisk walk...</td>\n",
       "      <td>[]</td>\n",
       "      <td>0_3_4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>[poor girl ! no wonder shes shy and retiring !]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0_35_3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>[gosh guess i tried to civilize these peo a li...</td>\n",
       "      <td>[]</td>\n",
       "      <td>1000_16_4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              dialog narration     img_id\n",
       "0  [ the chief mentioned that the place was deser...        []     0_19_3\n",
       "1          [disappoint you but id probably give you]        []     0_21_4\n",
       "2  [ah i feel better already now for a brisk walk...        []      0_3_4\n",
       "3    [poor girl ! no wonder shes shy and retiring !]        []     0_35_3\n",
       "4  [gosh guess i tried to civilize these peo a li...        []  1000_16_4"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transcription_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['0_19_3', '0_21_4', '0_3_4', ..., '929_19_0', '2945_30_1',\n",
       "       '330_37_0'], dtype=object)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transcription_df.img_id.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]                                                                                                                                                                                                                                                                                       4143\n",
       "['suddenly']                                                                                                                                                                                                                                                                                5\n",
       "['later']                                                                                                                                                                                                                                                                                   5\n",
       "['a few minutes later']                                                                                                                                                                                                                                                                     4\n",
       "['then']                                                                                                                                                                                                                                                                                    4\n",
       "                                                                                                                                                                                                                                                                                         ... \n",
       "[\" hen king richard left for the far east leading his crusaders his brother prince john took over taxess were raised . estates were seized ... but robin hood safe in sherwood forest , wasn ' t affected until he visited his beloved , maid marian at her father ' s castle ma n \"]       1\n",
       "['theka770ngmere 57ä¹ˆ mt4czu']                                                                                                                                                                                                                                                               1\n",
       "['gucikily ror me .. the elevator man diant orget to come for the bags !']                                                                                                                                                                                                                  1\n",
       "['he catches the heavytruck and throns / tback lantaaroad']                                                                                                                                                                                                                                 1\n",
       "[' without stopping the boat , the masked marvel grabs the singer , half - drowned , and drags him into the launch !']                                                                                                                                                                      1\n",
       "Name: narration, Length: 1939, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transcription_df.narration.astype(str).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]                                                                                                                                                                                           112\n",
       "[nan]                                                                                                                                                                                         20\n",
       "['help !']                                                                                                                                                                                     5\n",
       "['bang !']                                                                                                                                                                                     4\n",
       "['ugh !']                                                                                                                                                                                      4\n",
       "                                                                                                                                                                                            ... \n",
       "[\" hurry , boy this is what , we ve been waitin ' for \"]                                                                                                                                       1\n",
       "[\"head for that building sam don ' t spare the horses\", \"i ' m fryin in this dang tin suit but im a runnin\", 'what tme -- 7']                                                                  1\n",
       "['goodbye', ' oh ,']                                                                                                                                                                           1\n",
       "[' ha hi i am stronger than you thoughti and if i do not kill you , the screaming creatures will tear you apart because they obey only the whip with which creerley and 1 control them ']      1\n",
       "[' 5 . 1 arthin ssco os , the enmae arb4sëŠ” ']                                                                                                                                                  1\n",
       "Name: dialog, Length: 5958, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transcription_df.dialog.astype(str).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "transcription_df['text'] = transcription_df.apply(lambda x: x['dialog']+x['narration'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([list([' the chief mentioned that the place was deserted , but that doesnt seem to be the case !', 'maybe she thinks its a hotel or something !']),\n",
       "       list(['disappoint you but id probably give you']),\n",
       "       list(['ah i feel better already now for a brisk walk to calm my jangled nerves !']),\n",
       "       ...,\n",
       "       list([' and thats the whole jobin a nuar dap you handle its the first city bank ,... 1f you can try son not to leave as little money r but there as possible you see ithll the 8 now a help my chance of side d becomming the banks pres dent .', 'nut y it souni its darn easy to try fact but since you l the bo - 20 spl now about the side door']),\n",
       "       list([' only one thing to do , ellen ! draw him into the open - with ourselves as bait ', \"i don ' t know maybe you do\"]),\n",
       "       list(['hope this twelve hour hop means action'])], dtype=object)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transcription_df['text'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "transcription_df['text'] = transcription_df['text'].apply(lambda x: [y for y in x if type(y) == str])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def decontracted(phrase):\n",
    "    # specific\n",
    "    phrase = re.sub(r\"won\\'t\", \"will not\", phrase)\n",
    "    phrase = re.sub(r\"can\\'t\", \"can not\", phrase)\n",
    "\n",
    "    # general\n",
    "    phrase = re.sub(r\"n\\'t\", \" not\", phrase)\n",
    "    phrase = re.sub(r\"\\'re\", \" are\", phrase)\n",
    "    phrase = re.sub(r\"\\'s\", \" is\", phrase)\n",
    "    phrase = re.sub(r\"\\'d\", \" would\", phrase)\n",
    "    phrase = re.sub(r\"\\'ll\", \" will\", phrase)\n",
    "    phrase = re.sub(r\"\\'t\", \" not\", phrase)\n",
    "    phrase = re.sub(r\"\\'ve\", \" have\", phrase)\n",
    "    phrase = re.sub(r\"\\'m\", \" am\", phrase)\n",
    "    phrase = re.sub(r\"!\", \" !\", phrase)\n",
    "    phrase = re.sub(r\"\\.\", \" .\", phrase)\n",
    "    phrase = re.sub(r\",\", \" ,\", phrase)\n",
    "    return phrase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastpunct import FastPunct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "fastpunct = FastPunct()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"I guess the Australian government'll be glad to get this enemy base.\",\n",
       " \"Excuse you, but I'd probably give you.\",\n",
       " \"If you can try so not to leave as little money r but there as possible you see it he's now a help my chance of side d becoming the bank president.\",\n",
       " \"That dog risked his own life to save him! Guess that was exciting to watch I almost forgot all about the race! Who's leading?\"]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fastpunct.punct([\n",
    "                  \"i guess the australian government'll be glad to get this enemy base\",\n",
    "                   'disappoint you but id probably give you',\n",
    "                 '... 1f you can try son not to leave as little money r but there as possible you see ithll the 8 now a help my chance of side d becomming the banks pres dent .',\n",
    "                 \"that dog risked his own life to save him ! gosh that was exciting to watch i almost forgot all about the race ! whos leading ?\"], correct=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([list([\"The chief mentioned that the place was deserted, but that doesn't seem to be the case!\", \"Maybe she thinks it's a hotel or something!\"]),\n",
       "       list([\"Excuse you, but I'd probably give you.\"]),\n",
       "       list(['Ah I feel better already now for a brisk walk to calm my jangled nerves!']),\n",
       "       list([\"Poor girl! no wonder she's shy and retiring!\"]),\n",
       "       list(['Gosh guess I tried to civilize these people a little too fast and now I have to act unoe civilized in self defense!', 'Get the runt!', 'Let me at IIM.']),\n",
       "       list([\"I won't waste another minute.\", 'Women Your City is in the grip of a crime wave! Volunteer for police duty!']),\n",
       "       list(['A magnesium flare! Ohhhh.', \"A string is plucked, the minstrel's discharges a small capsule that goes into blinding brilliance,.\"]),\n",
       "       list(['Step in line and sink your calks up, men who fall out will beleft behind now.Excelsior!']),\n",
       "       list(['You said it would be suicide but he made it!', \"That dog risked his own life to save him! Guess that was exciting to watch I almost forgot all about the race! Who's leading?\"]),\n",
       "       list(['Now the problem is to see and not be seen!', '\"Swing Low still holds the lead!\" Carry me home is coming up behind him but the number one favorite \"Sweet Chariot\", seems to be lagging!'])],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transcription_df['text'][:10].apply(lambda x: fastpunct.punct(x,correct=True)).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "transcription_df = transcription_df[transcription_df['text'].astype(str)!='[]']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-884a4902785e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtranscription_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'text_clean'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtranscription_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfastpunct\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpunct\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcorrect\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/ml/lib/python3.6/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, convert_dtype, args, **kwds)\u001b[0m\n\u001b[1;32m   4040\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4041\u001b[0m                 \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4042\u001b[0;31m                 \u001b[0mmapped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_infer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconvert_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4043\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4044\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSeries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/lib.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m<ipython-input-30-884a4902785e>\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtranscription_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'text_clean'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtranscription_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfastpunct\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpunct\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcorrect\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/ml/lib/python3.6/site-packages/fastpunct/fastpunct.py\u001b[0m in \u001b[0;36mpunct\u001b[0;34m(self, sentences, beam_size, max_len, correct)\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m         output_ids = self.model.generate(\n\u001b[0;32m---> 88\u001b[0;31m             \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_beams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbeam_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_len\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m         )\n\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ml/lib/python3.6/site-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ml/lib/python3.6/site-packages/transformers/generation_utils.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, input_ids, max_length, min_length, do_sample, early_stopping, num_beams, temperature, top_k, top_p, repetition_penalty, bad_words_ids, bos_token_id, pad_token_id, eos_token_id, length_penalty, no_repeat_ngram_size, encoder_no_repeat_ngram_size, num_return_sequences, max_time, decoder_start_token_id, use_cache, num_beam_groups, diversity_penalty, prefix_allowed_tokens_fn, output_attentions, output_hidden_states, output_scores, return_dict_in_generate, forced_bos_token_id, forced_eos_token_id, remove_invalid_values, synced_gpus, **model_kwargs)\u001b[0m\n\u001b[1;32m   1042\u001b[0m                 \u001b[0mreturn_dict_in_generate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_dict_in_generate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1043\u001b[0m                 \u001b[0msynced_gpus\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msynced_gpus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1044\u001b[0;31m                 \u001b[0;34m**\u001b[0m\u001b[0mmodel_kwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1045\u001b[0m             )\n\u001b[1;32m   1046\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ml/lib/python3.6/site-packages/transformers/generation_utils.py\u001b[0m in \u001b[0;36mbeam_search\u001b[0;34m(self, input_ids, beam_scorer, logits_processor, stopping_criteria, max_length, pad_token_id, eos_token_id, output_attentions, output_hidden_states, output_scores, return_dict_in_generate, synced_gpus, **model_kwargs)\u001b[0m\n\u001b[1;32m   1826\u001b[0m                 \u001b[0mnext_indices\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1827\u001b[0m                 \u001b[0mpad_token_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpad_token_id\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1828\u001b[0;31m                 \u001b[0meos_token_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0meos_token_id\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1829\u001b[0m             )\n\u001b[1;32m   1830\u001b[0m             \u001b[0mbeam_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbeam_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"next_beam_scores\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ml/lib/python3.6/site-packages/transformers/generation_beam_search.py\u001b[0m in \u001b[0;36mprocess\u001b[0;34m(self, input_ids, next_scores, next_tokens, next_indices, pad_token_id, eos_token_id)\u001b[0m\n\u001b[1;32m    243\u001b[0m                 \u001b[0mbatch_beam_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_idx\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroup_size\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnext_index\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m                 \u001b[0;31m# add to generated hypotheses if end of sentence\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 245\u001b[0;31m                 \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0meos_token_id\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnext_token\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0meos_token_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    246\u001b[0m                     \u001b[0;31m# if beam_token does not belong to top num_beams tokens, it should not be added\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m                     \u001b[0mis_beam_token_worse_than_top_num_beams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbeam_token_rank\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroup_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# transcription_df['text_clean'] = transcription_df['text'].apply(lambda x: fastpunct.punct(x,correct=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transcription_df[['text','text_clean']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transcription_df['text_clean'] = transcription_df['text_clean'].apply(lambda x: [decontracted(y).lower() for y in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transcription_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transcription_df.columns = ['dialog', 'narration', 'image_id', 'text','text_clean']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transcription_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(transcription_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.merge(label_df,transcription_df,on='image_id',how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emotions = ['Angry','Disgust','Fear','Happy','Sad','Surprise','Neutral','Others']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['emotion_list'] = df.apply(lambda x: [emo for emo in emotions if x[emo] == '1'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('../data/public_train/dataset.csv',index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train, test = train_test_split(df, test_size=0.2)\n",
    "train, val = train_test_split(train, test_size=0.1)\n",
    "print(type(train), type(test), type(val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val = val.reset_index(drop=True)\n",
    "test = test.reset_index(drop=True)\n",
    "train = train.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val.to_csv(\"../data/public_train/val_data.csv\",index=None)\n",
    "test.to_csv(\"../data/public_train/test_data.csv\",index=None)\n",
    "train.to_csv(\"../data/public_train/train_data.csv\",index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "val=pd.read_csv(\"../data/public_train/val_data.csv\")\n",
    "test=pd.read_csv(\"../data/public_train/test_data.csv\")\n",
    "train=pd.read_csv(\"../data/public_train/train_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "def resize_img(path):\n",
    "  try:\n",
    "    img = cv2.imread(path)\n",
    "    img = cv2.resize(img, (224, 224))\n",
    "    img = img.astype(np.float32)/255\n",
    "    return img\n",
    "  except Exception as e:\n",
    "    print(str(e))\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = '../data/public_train/train/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing i: 0 ../data/public_train/train/1179_7_2.jpg\n",
      "Processing i: 100 ../data/public_train/train/1774_32_5.jpg\n",
      "Processing i: 200 ../data/public_train/train/3083_44_2.jpg\n",
      "Processing i: 300 ../data/public_train/train/1584_25_6.jpg\n",
      "Processing i: 400 ../data/public_train/train/2252_54_2.jpg\n"
     ]
    }
   ],
   "source": [
    "val_imgs = []\n",
    "i = 0\n",
    "for index, row in val.iterrows():\n",
    "  if i%100 == 0:\n",
    "    print(\"Processing i:\", i, base_path+str(row['image_id'])+'.jpg')\n",
    "  img = resize_img(base_path+str(row['image_id'])+'.jpg')\n",
    "  if img is not None:\n",
    "    val_imgs.append(img)\n",
    "  else:\n",
    "#     val = val.drop(index)\n",
    "    print(\"Dropping row:\", index, \"Length:\", len(val))\n",
    "  i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(val) == len(val_imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(486, 224, 224, 3)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_np_imgs = np.array(val_imgs)\n",
    "val_np_imgs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/public_train/val_np_img_norm','wb') as f: pickle.dump(val_np_imgs, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing i: 0 ../data/public_train/train/1308_48_2.jpg\n",
      "Processing i: 100 ../data/public_train/train/3592_41_5.jpg\n",
      "Processing i: 200 ../data/public_train/train/1555_21_3.jpg\n",
      "Processing i: 300 ../data/public_train/train/1146_21_3.jpg\n",
      "Processing i: 400 ../data/public_train/train/211_94_3.jpg\n",
      "Processing i: 500 ../data/public_train/train/714_33_9.jpg\n",
      "Processing i: 600 ../data/public_train/train/1890_48_1.jpg\n",
      "Processing i: 700 ../data/public_train/train/1079_22_2.jpg\n",
      "Processing i: 800 ../data/public_train/train/2257_64_1.jpg\n",
      "Processing i: 900 ../data/public_train/train/1091_7_0.jpg\n",
      "Processing i: 1000 ../data/public_train/train/3117_48_6.jpg\n",
      "Processing i: 1100 ../data/public_train/train/3753_58_3.jpg\n",
      "Processing i: 1200 ../data/public_train/train/2143_47_7.jpg\n",
      "Processing i: 1300 ../data/public_train/train/3754_12_3.jpg\n",
      "Processing i: 1400 ../data/public_train/train/1630_47_5.jpg\n",
      "Processing i: 1500 ../data/public_train/train/3663_5_2.jpg\n",
      "Processing i: 1600 ../data/public_train/train/2544_6_0.jpg\n",
      "Processing i: 1700 ../data/public_train/train/3581_25_6.jpg\n",
      "Processing i: 1800 ../data/public_train/train/1709_45_3.jpg\n",
      "Processing i: 1900 ../data/public_train/train/2800_10_2.jpg\n",
      "Processing i: 2000 ../data/public_train/train/2012_29_6.jpg\n",
      "Processing i: 2100 ../data/public_train/train/2304_46_4.jpg\n",
      "Processing i: 2200 ../data/public_train/train/630_46_2.jpg\n",
      "Processing i: 2300 ../data/public_train/train/331_27_5.jpg\n",
      "Processing i: 2400 ../data/public_train/train/3569_18_0.jpg\n",
      "Processing i: 2500 ../data/public_train/train/2281_21_3.jpg\n",
      "Processing i: 2600 ../data/public_train/train/2633_18_6.jpg\n",
      "Processing i: 2700 ../data/public_train/train/3766_18_5.jpg\n",
      "Processing i: 2800 ../data/public_train/train/3094_30_2.jpg\n",
      "Processing i: 2900 ../data/public_train/train/1584_52_2.jpg\n",
      "Processing i: 3000 ../data/public_train/train/1289_10_1.jpg\n",
      "Processing i: 3100 ../data/public_train/train/1091_25_4.jpg\n",
      "Processing i: 3200 ../data/public_train/train/2325_63_1.jpg\n",
      "Processing i: 3300 ../data/public_train/train/1287_53_4.jpg\n",
      "Processing i: 3400 ../data/public_train/train/3832_25_3.jpg\n",
      "Processing i: 3500 ../data/public_train/train/196_40_1.jpg\n",
      "Processing i: 3600 ../data/public_train/train/3326_32_4.jpg\n",
      "Processing i: 3700 ../data/public_train/train/3064_54_4.jpg\n",
      "Processing i: 3800 ../data/public_train/train/717_46_1.jpg\n",
      "Processing i: 3900 ../data/public_train/train/830_16_1.jpg\n",
      "Processing i: 4000 ../data/public_train/train/3352_9_6.jpg\n",
      "Processing i: 4100 ../data/public_train/train/671_59_4.jpg\n",
      "Processing i: 4200 ../data/public_train/train/2685_38_0.jpg\n",
      "Processing i: 4300 ../data/public_train/train/1060_14_5.jpg\n"
     ]
    }
   ],
   "source": [
    "train_imgs = []\n",
    "i = 0\n",
    "for index, row in train.iterrows():\n",
    "  if i%100 == 0:\n",
    "    print(\"Processing i:\", i, base_path+str(row['image_id'])+'.jpg')\n",
    "  img = resize_img(base_path+str(row['image_id'])+'.jpg')\n",
    "  if img is not None:\n",
    "    train_imgs.append(img)\n",
    "  else:\n",
    "#     train = train.drop(index)\n",
    "    print(\"Dropping row:\", index, \"Length:\", len(train))\n",
    "  i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4365, 224, 224, 3)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_np_imgs = np.array(train_imgs)\n",
    "train_np_imgs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/public_train/train_np_img_norm','wb') as f: pickle.dump(train_np_imgs, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(train) == len(train_imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing i: 0 ../data/public_train/train/3812_3_3.jpg\n",
      "Processing i: 100 ../data/public_train/train/1906_25_6.jpg\n",
      "Processing i: 200 ../data/public_train/train/2399_62_5.jpg\n",
      "Processing i: 300 ../data/public_train/train/1514_3_5.jpg\n",
      "Processing i: 400 ../data/public_train/train/1634_41_5.jpg\n",
      "Processing i: 500 ../data/public_train/train/567_11_0.jpg\n",
      "Processing i: 600 ../data/public_train/train/2279_33_3.jpg\n",
      "Processing i: 700 ../data/public_train/train/966_19_5.jpg\n",
      "Processing i: 800 ../data/public_train/train/2319_31_1.jpg\n",
      "Processing i: 900 ../data/public_train/train/3075_27_4.jpg\n",
      "Processing i: 1000 ../data/public_train/train/2805_31_6.jpg\n",
      "Processing i: 1100 ../data/public_train/train/1190_23_3.jpg\n",
      "Processing i: 1200 ../data/public_train/train/1125_7_5.jpg\n"
     ]
    }
   ],
   "source": [
    "test_imgs = []\n",
    "i = 0\n",
    "for index, row in test.iterrows():\n",
    "  if i%100 == 0:\n",
    "    print(\"Processing i:\", i, base_path+str(row['image_id'])+'.jpg')\n",
    "  img = resize_img(base_path+str(row['image_id'])+'.jpg')\n",
    "  if img is not None:\n",
    "    test_imgs.append(img)\n",
    "  else:\n",
    "#     test = test.drop(index)\n",
    "    print(\"Dropping row:\", index, \"Length:\", len(test))\n",
    "  i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(test) == len(test_imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1213, 224, 224, 3)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_np_imgs = np.array(test_imgs)\n",
    "test_np_imgs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/public_train/test_np_img_norm','wb') as f: pickle.dump(test_np_imgs, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
