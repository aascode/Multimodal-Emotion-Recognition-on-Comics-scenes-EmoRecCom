{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m5tUoHe9FRhs"
   },
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Dr7BCHS-nIRW",
    "outputId": "97b5954d-b5ed-4e7d-d4d6-467338460082",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.models as models\n",
    "from efficientnet_pytorch import EfficientNet\n",
    "from torch.nn import BCEWithLogitsLoss, BCELoss\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.metrics import classification_report, confusion_matrix, multilabel_confusion_matrix, f1_score, accuracy_score, roc_auc_score\n",
    "import pickle\n",
    "from transformers import RobertaTokenizer,RobertaModel, XLNetTokenizer, RobertaTokenizer, BertForSequenceClassification, XLNetForSequenceClassification, RobertaModel, AdamW\n",
    "from tqdm import tqdm, trange\n",
    "from ast import literal_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "zB5Dij6JuItX"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UhjnJEwKnISB",
    "outputId": "c2cbeb3d-3c57-4257-d478-ef909dd33b94"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found GPU at: /device:GPU:0\n"
     ]
    }
   ],
   "source": [
    "device_name = tf.test.gpu_device_name()\n",
    "if device_name != '/device:GPU:0':\n",
    "  raise SystemError('GPU device not found')\n",
    "print('Found GPU at: {}'.format(device_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "uorMX_zrnISM",
    "outputId": "8f87795c-c87b-4b99-b996-d9276714feed",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'GeForce GTX 1060'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "n_gpu = torch.cuda.device_count()\n",
    "torch.cuda.get_device_name(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dLcetMjZFjSH"
   },
   "source": [
    "## Load and Preprocess Training Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2dal0ggBcYdD"
   },
   "source": [
    "Dataset will be tokenized then split into training and validation sets. The validation set will be used to monitor training. For testing a separate test set will be loaded for analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_size = 4365 #4365"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4365, 224, 224, 3)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('../data/public_train/train_np_img_norm','rb') as f: X_img_train = pickle.load(f)\n",
    "X_img_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1213, 224, 224, 3)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('../data/public_train/test_np_img_norm', 'rb') as f: X_img_test = pickle.load(f)\n",
    "X_img_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(486, 224, 224, 3)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('../data/public_train/val_np_img_norm', 'rb') as f: X_img_val = pickle.load(f)\n",
    "X_img_val.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_img_train = X_img_train[:sample_size]\n",
    "X_img_val = X_img_val\n",
    "X_img_test = X_img_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(486, 3, 224, 224)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_img_val = np.reshape(X_img_val, (X_img_val.shape[0], 3, 224, 224))\n",
    "X_img_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_img_test = np.reshape(X_img_test, (X_img_test.shape[0], 3, 224, 224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_img_train = np.reshape(X_img_train, (X_img_train.shape[0], 3, 224, 224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 340
    },
    "id": "0ecREc7GnISW",
    "outputId": "791a61a7-a4c1-488f-dad7-8635f1fd19da",
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>image_id</th>\n",
       "      <th>Angry</th>\n",
       "      <th>Disgust</th>\n",
       "      <th>Fear</th>\n",
       "      <th>Happy</th>\n",
       "      <th>Sad</th>\n",
       "      <th>Surprise</th>\n",
       "      <th>Neutral</th>\n",
       "      <th>Others</th>\n",
       "      <th>dialog</th>\n",
       "      <th>narration</th>\n",
       "      <th>text</th>\n",
       "      <th>text_clean</th>\n",
       "      <th>emotion_list</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>575.0</td>\n",
       "      <td>1308_48_2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>['wait a minute im not going to hurt you !']</td>\n",
       "      <td>[]</td>\n",
       "      <td>['wait a minute im not going to hurt you !']</td>\n",
       "      <td>['wait a minute i am not going to hurt you   !']</td>\n",
       "      <td>['Angry', 'Happy']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>5395.0</td>\n",
       "      <td>3766_29_2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[' hear that trody ? they meed a nsw carew maa...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[' hear that trody ? they meed a nsw carew maa...</td>\n",
       "      <td>['he thought they need a new careman , looks l...</td>\n",
       "      <td>['Disgust', 'Happy', 'Neutral']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2004.0</td>\n",
       "      <td>2112_17_7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>['the comet leaps into action his bouyancy all...</td>\n",
       "      <td>['the comet leaps into action his bouyancy all...</td>\n",
       "      <td>['the comet leaps into action his bouyancy all...</td>\n",
       "      <td>['the comet leaps into action , his bouyancy a...</td>\n",
       "      <td>['Angry', 'Disgust']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4863.0</td>\n",
       "      <td>3458_16_7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>['its in there . isnt mate ?', \"yeah - t ' s i...</td>\n",
       "      <td>[]</td>\n",
       "      <td>['its in there . isnt mate ?', \"yeah - t ' s i...</td>\n",
       "      <td>['is it there   .is not mate?', 'yeah t is in ...</td>\n",
       "      <td>['Neutral']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5146.0</td>\n",
       "      <td>2338_19_3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>['listen und pass der yord along . bzzzz21', '...</td>\n",
       "      <td>[]</td>\n",
       "      <td>['listen und pass der yord along . bzzzz21', '...</td>\n",
       "      <td>['listen and pass your way   . bzzzz21   .', '...</td>\n",
       "      <td>['Fear', 'Surprise', 'Neutral']</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id   image_id  Angry  Disgust  Fear  Happy  Sad  Surprise  Neutral  \\\n",
       "0   575.0  1308_48_2      1        0     0      1    0         0        0   \n",
       "1  5395.0  3766_29_2      0        1     0      1    0         0        1   \n",
       "2  2004.0  2112_17_7      1        1     0      0    0         0        0   \n",
       "3  4863.0  3458_16_7      0        0     0      0    0         0        1   \n",
       "4  5146.0  2338_19_3      0        0     1      0    0         1        1   \n",
       "\n",
       "   Others                                             dialog  \\\n",
       "0       0       ['wait a minute im not going to hurt you !']   \n",
       "1       0  [' hear that trody ? they meed a nsw carew maa...   \n",
       "2       0  ['the comet leaps into action his bouyancy all...   \n",
       "3       0  ['its in there . isnt mate ?', \"yeah - t ' s i...   \n",
       "4       0  ['listen und pass der yord along . bzzzz21', '...   \n",
       "\n",
       "                                           narration  \\\n",
       "0                                                 []   \n",
       "1                                                 []   \n",
       "2  ['the comet leaps into action his bouyancy all...   \n",
       "3                                                 []   \n",
       "4                                                 []   \n",
       "\n",
       "                                                text  \\\n",
       "0       ['wait a minute im not going to hurt you !']   \n",
       "1  [' hear that trody ? they meed a nsw carew maa...   \n",
       "2  ['the comet leaps into action his bouyancy all...   \n",
       "3  ['its in there . isnt mate ?', \"yeah - t ' s i...   \n",
       "4  ['listen und pass der yord along . bzzzz21', '...   \n",
       "\n",
       "                                          text_clean  \\\n",
       "0   ['wait a minute i am not going to hurt you   !']   \n",
       "1  ['he thought they need a new careman , looks l...   \n",
       "2  ['the comet leaps into action , his bouyancy a...   \n",
       "3  ['is it there   .is not mate?', 'yeah t is in ...   \n",
       "4  ['listen and pass your way   . bzzzz21   .', '...   \n",
       "\n",
       "                      emotion_list  \n",
       "0               ['Angry', 'Happy']  \n",
       "1  ['Disgust', 'Happy', 'Neutral']  \n",
       "2             ['Angry', 'Disgust']  \n",
       "3                      ['Neutral']  \n",
       "4  ['Fear', 'Surprise', 'Neutral']  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../data/public_train/train_data.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4365"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[:sample_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6AhWrzX7nITB",
    "outputId": "972b4db0-86d5-4553-a8c1-51415a409566"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique comments:  False\n",
      "Null values:  False\n"
     ]
    }
   ],
   "source": [
    "print('Unique ocr_texts: ', df.text_clean.nunique() == df.shape[0])\n",
    "print('Null values: ', df.isnull().values.any())\n",
    "# df[df.isna().any(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OkKpz_9eJRt7",
    "outputId": "4745fb8b-c3ee-4218-f7ef-ae9343517f64"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average sentence length:  25.596334478808707\n",
      "stdev sentence length:  24.795639258733278\n"
     ]
    }
   ],
   "source": [
    "print('average sentence length: ', df.text_clean.str.split().str.len().mean())\n",
    "print('stdev sentence length: ', df.text_clean.str.split().str.len().std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UVI59S9VaAfB",
    "outputId": "518cce78-c9c5-47d0-a9ea-ef422c6a7628"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label columns:  ['Angry', 'Disgust', 'Fear', 'Happy', 'Sad', 'Surprise', 'Neutral', 'Others']\n"
     ]
    }
   ],
   "source": [
    "cols = df.columns\n",
    "label_cols = list(cols[2:10])\n",
    "num_labels = len(label_cols)\n",
    "print('Label columns: ', label_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xzgA5qQgYIBZ",
    "outputId": "3c4f0667-d436-44d0-9dc9-8b4434df3b9c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count of 1 per label: \n",
      " Angry       1746\n",
      "Disgust     1589\n",
      "Fear        1472\n",
      "Happy       1776\n",
      "Sad          632\n",
      "Surprise    1502\n",
      "Neutral     2962\n",
      "Others       303\n",
      "dtype: int64 \n",
      "\n",
      "Count of 0 per label: \n",
      " Angry       2619\n",
      "Disgust     2776\n",
      "Fear        2893\n",
      "Happy       2589\n",
      "Sad         3733\n",
      "Surprise    2863\n",
      "Neutral     1403\n",
      "Others      4062\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print('Count of 1 per label: \\n', df[label_cols].sum(), '\\n') # Label counts, may need to downsample or upsample\n",
    "print('Count of 0 per label: \\n', df[label_cols].eq(0).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "uFpSd4JzaAae"
   },
   "outputs": [],
   "source": [
    "# df = df.sample(frac=1).reset_index(drop=True) #shuffle rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 391
    },
    "id": "0DF3ddjej5vd",
    "outputId": "13270850-dae3-466b-d371-6d533a8c745f"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>image_id</th>\n",
       "      <th>Angry</th>\n",
       "      <th>Disgust</th>\n",
       "      <th>Fear</th>\n",
       "      <th>Happy</th>\n",
       "      <th>Sad</th>\n",
       "      <th>Surprise</th>\n",
       "      <th>Neutral</th>\n",
       "      <th>Others</th>\n",
       "      <th>dialog</th>\n",
       "      <th>narration</th>\n",
       "      <th>text</th>\n",
       "      <th>text_clean</th>\n",
       "      <th>emotion_list</th>\n",
       "      <th>one_hot_labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>575.0</td>\n",
       "      <td>1308_48_2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>['wait a minute im not going to hurt you !']</td>\n",
       "      <td>[]</td>\n",
       "      <td>['wait a minute im not going to hurt you !']</td>\n",
       "      <td>['wait a minute i am not going to hurt you   !']</td>\n",
       "      <td>['Angry', 'Happy']</td>\n",
       "      <td>[1, 0, 0, 1, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>5395.0</td>\n",
       "      <td>3766_29_2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[' hear that trody ? they meed a nsw carew maa...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[' hear that trody ? they meed a nsw carew maa...</td>\n",
       "      <td>['he thought they need a new careman , looks l...</td>\n",
       "      <td>['Disgust', 'Happy', 'Neutral']</td>\n",
       "      <td>[0, 1, 0, 1, 0, 0, 1, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2004.0</td>\n",
       "      <td>2112_17_7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>['the comet leaps into action his bouyancy all...</td>\n",
       "      <td>['the comet leaps into action his bouyancy all...</td>\n",
       "      <td>['the comet leaps into action his bouyancy all...</td>\n",
       "      <td>['the comet leaps into action , his bouyancy a...</td>\n",
       "      <td>['Angry', 'Disgust']</td>\n",
       "      <td>[1, 1, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4863.0</td>\n",
       "      <td>3458_16_7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>['its in there . isnt mate ?', \"yeah - t ' s i...</td>\n",
       "      <td>[]</td>\n",
       "      <td>['its in there . isnt mate ?', \"yeah - t ' s i...</td>\n",
       "      <td>['is it there   .is not mate?', 'yeah t is in ...</td>\n",
       "      <td>['Neutral']</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 1, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5146.0</td>\n",
       "      <td>2338_19_3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>['listen und pass der yord along . bzzzz21', '...</td>\n",
       "      <td>[]</td>\n",
       "      <td>['listen und pass der yord along . bzzzz21', '...</td>\n",
       "      <td>['listen and pass your way   . bzzzz21   .', '...</td>\n",
       "      <td>['Fear', 'Surprise', 'Neutral']</td>\n",
       "      <td>[0, 0, 1, 0, 0, 1, 1, 0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id   image_id  Angry  Disgust  Fear  Happy  Sad  Surprise  Neutral  \\\n",
       "0   575.0  1308_48_2      1        0     0      1    0         0        0   \n",
       "1  5395.0  3766_29_2      0        1     0      1    0         0        1   \n",
       "2  2004.0  2112_17_7      1        1     0      0    0         0        0   \n",
       "3  4863.0  3458_16_7      0        0     0      0    0         0        1   \n",
       "4  5146.0  2338_19_3      0        0     1      0    0         1        1   \n",
       "\n",
       "   Others                                             dialog  \\\n",
       "0       0       ['wait a minute im not going to hurt you !']   \n",
       "1       0  [' hear that trody ? they meed a nsw carew maa...   \n",
       "2       0  ['the comet leaps into action his bouyancy all...   \n",
       "3       0  ['its in there . isnt mate ?', \"yeah - t ' s i...   \n",
       "4       0  ['listen und pass der yord along . bzzzz21', '...   \n",
       "\n",
       "                                           narration  \\\n",
       "0                                                 []   \n",
       "1                                                 []   \n",
       "2  ['the comet leaps into action his bouyancy all...   \n",
       "3                                                 []   \n",
       "4                                                 []   \n",
       "\n",
       "                                                text  \\\n",
       "0       ['wait a minute im not going to hurt you !']   \n",
       "1  [' hear that trody ? they meed a nsw carew maa...   \n",
       "2  ['the comet leaps into action his bouyancy all...   \n",
       "3  ['its in there . isnt mate ?', \"yeah - t ' s i...   \n",
       "4  ['listen und pass der yord along . bzzzz21', '...   \n",
       "\n",
       "                                          text_clean  \\\n",
       "0   ['wait a minute i am not going to hurt you   !']   \n",
       "1  ['he thought they need a new careman , looks l...   \n",
       "2  ['the comet leaps into action , his bouyancy a...   \n",
       "3  ['is it there   .is not mate?', 'yeah t is in ...   \n",
       "4  ['listen and pass your way   . bzzzz21   .', '...   \n",
       "\n",
       "                      emotion_list            one_hot_labels  \n",
       "0               ['Angry', 'Happy']  [1, 0, 0, 1, 0, 0, 0, 0]  \n",
       "1  ['Disgust', 'Happy', 'Neutral']  [0, 1, 0, 1, 0, 0, 1, 0]  \n",
       "2             ['Angry', 'Disgust']  [1, 1, 0, 0, 0, 0, 0, 0]  \n",
       "3                      ['Neutral']  [0, 0, 0, 0, 0, 0, 1, 0]  \n",
       "4  ['Fear', 'Surprise', 'Neutral']  [0, 0, 1, 0, 0, 1, 1, 0]  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['one_hot_labels'] = list(df[label_cols].values)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "MlhHifh5bW7e"
   },
   "outputs": [],
   "source": [
    "train_labels = list(df.one_hot_labels.values)\n",
    "ocr_texts = list(df.text_clean.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IlMHfElhGJzc"
   },
   "source": [
    "Load the pretrained tokenizer that corresponds to your choice in model. e.g.,\n",
    "\n",
    "```\n",
    "BERT:\n",
    "tokenizer = RobertaTokenizer.from_pretrained('roberta-base', do_lower_case=True) \n",
    "\n",
    "XLNet:\n",
    "tokenizer = XLNetTokenizer.from_pretrained('xlnet-base-cased', do_lower_case=False) \n",
    "\n",
    "RoBERTa:\n",
    "tokenizer = RobertaTokenizer.from_pretrained('roberta-base', do_lower_case=False)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IhVr8SziL_PY"
   },
   "source": [
    "In order to avoid memory issues with Google Colab, I enforce a max_length of 100 tokens. Note that some sentences may not adequately represent each label because of this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HNsEu-vUur-4",
    "outputId": "baf4e3f3-6015-4419-dce0-f4125bbdcbad"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/shwetkm/anaconda3/envs/ml/lib/python3.6/site-packages/transformers/tokenization_utils_base.py:2110: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  FutureWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokenizer outputs:  dict_keys(['input_ids', 'attention_mask'])\n"
     ]
    }
   ],
   "source": [
    "max_length = 35\n",
    "tokenizer = RobertaTokenizer.from_pretrained('roberta-base', do_lower_case=True) # tokenizer\n",
    "encodings = tokenizer.batch_encode_plus(ocr_texts,max_length=max_length,pad_to_max_length=True) # tokenizer's encoding method\n",
    "print('tokenizer outputs: ', encodings.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['input_ids', 'attention_mask'])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encodings.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "l6CCLSjfur-9"
   },
   "outputs": [],
   "source": [
    "train_inputs = encodings['input_ids'] # tokenized and encoded sentences\n",
    "# train_token_types = encodings['token_type_ids'] # token type ids\n",
    "train_masks = encodings['attention_mask'] # attention masks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r9PxAt48HRRj"
   },
   "source": [
    "Be sure to handle all classes during validation using \"stratify\" during train/validation split:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "WPFaq4ufnIT2"
   },
   "outputs": [],
   "source": [
    "# Convert all of our data into torch tensors, the required datatype for our model\n",
    "train_inputs = torch.tensor(train_inputs)\n",
    "train_labels = torch.tensor(train_labels)\n",
    "train_masks = torch.tensor(train_masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 391
    },
    "id": "G5Q7hC4GFOLJ",
    "outputId": "5cb49a39-b967-43f8-9cea-c97d027e194e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Null values:  False\n",
      "Same columns between train and validation:  True\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>image_id</th>\n",
       "      <th>Angry</th>\n",
       "      <th>Disgust</th>\n",
       "      <th>Fear</th>\n",
       "      <th>Happy</th>\n",
       "      <th>Sad</th>\n",
       "      <th>Surprise</th>\n",
       "      <th>Neutral</th>\n",
       "      <th>Others</th>\n",
       "      <th>dialog</th>\n",
       "      <th>narration</th>\n",
       "      <th>text</th>\n",
       "      <th>text_clean</th>\n",
       "      <th>emotion_list</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>340.0</td>\n",
       "      <td>1179_7_2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>['oops ! cheap twine or must have gained weigh...</td>\n",
       "      <td>['plummets down', 'he vaul7 front']</td>\n",
       "      <td>['oops ! cheap twine or must have gained weigh...</td>\n",
       "      <td>['ops   ! cheap twine or must have gained weig...</td>\n",
       "      <td>['Sad', 'Surprise']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3831.0</td>\n",
       "      <td>2258_29_2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[' just a minute , you ...']</td>\n",
       "      <td>[]</td>\n",
       "      <td>[' just a minute , you ...']</td>\n",
       "      <td>['just a minute , you   .   .   .   .']</td>\n",
       "      <td>['Angry', 'Disgust', 'Fear', 'Happy', 'Neutral']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2465.0</td>\n",
       "      <td>3832_23_3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[\"they think they bungled and are going to rep...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[\"they think they bungled and are going to rep...</td>\n",
       "      <td>['they think they bungled and are going to rep...</td>\n",
       "      <td>['Angry', 'Disgust', 'Sad', 'Neutral']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>672.0</td>\n",
       "      <td>1377_39_7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>['owuch']</td>\n",
       "      <td>[]</td>\n",
       "      <td>['owuch']</td>\n",
       "      <td>['wow   .']</td>\n",
       "      <td>['Angry', 'Surprise', 'Neutral']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5145.0</td>\n",
       "      <td>777_20_0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[\"look nightmare ! o he ' s gone through w the...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[\"look nightmare ! o he ' s gone through w the...</td>\n",
       "      <td>['look nightmare   ! he is gone through the we...</td>\n",
       "      <td>['Angry', 'Neutral']</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id   image_id  Angry  Disgust  Fear  Happy  Sad  Surprise  Neutral  \\\n",
       "0   340.0   1179_7_2      0        0     0      0    1         1        0   \n",
       "1  3831.0  2258_29_2      1        1     1      1    0         0        1   \n",
       "2  2465.0  3832_23_3      1        1     0      0    1         0        1   \n",
       "3   672.0  1377_39_7      1        0     0      0    0         1        1   \n",
       "4  5145.0   777_20_0      1        0     0      0    0         0        1   \n",
       "\n",
       "   Others                                             dialog  \\\n",
       "0       0  ['oops ! cheap twine or must have gained weigh...   \n",
       "1       0                       [' just a minute , you ...']   \n",
       "2       0  [\"they think they bungled and are going to rep...   \n",
       "3       0                                          ['owuch']   \n",
       "4       0  [\"look nightmare ! o he ' s gone through w the...   \n",
       "\n",
       "                             narration  \\\n",
       "0  ['plummets down', 'he vaul7 front']   \n",
       "1                                   []   \n",
       "2                                   []   \n",
       "3                                   []   \n",
       "4                                   []   \n",
       "\n",
       "                                                text  \\\n",
       "0  ['oops ! cheap twine or must have gained weigh...   \n",
       "1                       [' just a minute , you ...']   \n",
       "2  [\"they think they bungled and are going to rep...   \n",
       "3                                          ['owuch']   \n",
       "4  [\"look nightmare ! o he ' s gone through w the...   \n",
       "\n",
       "                                          text_clean  \\\n",
       "0  ['ops   ! cheap twine or must have gained weig...   \n",
       "1            ['just a minute , you   .   .   .   .']   \n",
       "2  ['they think they bungled and are going to rep...   \n",
       "3                                        ['wow   .']   \n",
       "4  ['look nightmare   ! he is gone through the we...   \n",
       "\n",
       "                                       emotion_list  \n",
       "0                               ['Sad', 'Surprise']  \n",
       "1  ['Angry', 'Disgust', 'Fear', 'Happy', 'Neutral']  \n",
       "2            ['Angry', 'Disgust', 'Sad', 'Neutral']  \n",
       "3                  ['Angry', 'Surprise', 'Neutral']  \n",
       "4                              ['Angry', 'Neutral']  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_df = pd.read_csv('../data/public_train/val_data.csv')\n",
    "# validation_labels_df = pd.read_csv('validation_labels.csv')\n",
    "# validation_df = validation_df.merge(validation_labels_df, on='id', how='left')\n",
    "validation_label_cols = list(validation_df.columns[2:10])\n",
    "print('Null values: ', validation_df.isnull().values.any()) #should not be any null sentences or labels\n",
    "print('Same columns between train and validation: ', label_cols == validation_label_cols) #columns should be the same\n",
    "validation_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 391
    },
    "id": "77rjCrMGpYxz",
    "outputId": "d9682639-991e-472c-d07f-33336b85f589"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>image_id</th>\n",
       "      <th>Angry</th>\n",
       "      <th>Disgust</th>\n",
       "      <th>Fear</th>\n",
       "      <th>Happy</th>\n",
       "      <th>Sad</th>\n",
       "      <th>Surprise</th>\n",
       "      <th>Neutral</th>\n",
       "      <th>Others</th>\n",
       "      <th>dialog</th>\n",
       "      <th>narration</th>\n",
       "      <th>text</th>\n",
       "      <th>text_clean</th>\n",
       "      <th>emotion_list</th>\n",
       "      <th>one_hot_labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>340.0</td>\n",
       "      <td>1179_7_2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>['oops ! cheap twine or must have gained weigh...</td>\n",
       "      <td>['plummets down', 'he vaul7 front']</td>\n",
       "      <td>['oops ! cheap twine or must have gained weigh...</td>\n",
       "      <td>['ops   ! cheap twine or must have gained weig...</td>\n",
       "      <td>['Sad', 'Surprise']</td>\n",
       "      <td>[0, 0, 0, 0, 1, 1, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3831.0</td>\n",
       "      <td>2258_29_2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[' just a minute , you ...']</td>\n",
       "      <td>[]</td>\n",
       "      <td>[' just a minute , you ...']</td>\n",
       "      <td>['just a minute , you   .   .   .   .']</td>\n",
       "      <td>['Angry', 'Disgust', 'Fear', 'Happy', 'Neutral']</td>\n",
       "      <td>[1, 1, 1, 1, 0, 0, 1, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2465.0</td>\n",
       "      <td>3832_23_3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[\"they think they bungled and are going to rep...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[\"they think they bungled and are going to rep...</td>\n",
       "      <td>['they think they bungled and are going to rep...</td>\n",
       "      <td>['Angry', 'Disgust', 'Sad', 'Neutral']</td>\n",
       "      <td>[1, 1, 0, 0, 1, 0, 1, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>672.0</td>\n",
       "      <td>1377_39_7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>['owuch']</td>\n",
       "      <td>[]</td>\n",
       "      <td>['owuch']</td>\n",
       "      <td>['wow   .']</td>\n",
       "      <td>['Angry', 'Surprise', 'Neutral']</td>\n",
       "      <td>[1, 0, 0, 0, 0, 1, 1, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5145.0</td>\n",
       "      <td>777_20_0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[\"look nightmare ! o he ' s gone through w the...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[\"look nightmare ! o he ' s gone through w the...</td>\n",
       "      <td>['look nightmare   ! he is gone through the we...</td>\n",
       "      <td>['Angry', 'Neutral']</td>\n",
       "      <td>[1, 0, 0, 0, 0, 0, 1, 0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id   image_id  Angry  Disgust  Fear  Happy  Sad  Surprise  Neutral  \\\n",
       "0   340.0   1179_7_2      0        0     0      0    1         1        0   \n",
       "1  3831.0  2258_29_2      1        1     1      1    0         0        1   \n",
       "2  2465.0  3832_23_3      1        1     0      0    1         0        1   \n",
       "3   672.0  1377_39_7      1        0     0      0    0         1        1   \n",
       "4  5145.0   777_20_0      1        0     0      0    0         0        1   \n",
       "\n",
       "   Others                                             dialog  \\\n",
       "0       0  ['oops ! cheap twine or must have gained weigh...   \n",
       "1       0                       [' just a minute , you ...']   \n",
       "2       0  [\"they think they bungled and are going to rep...   \n",
       "3       0                                          ['owuch']   \n",
       "4       0  [\"look nightmare ! o he ' s gone through w the...   \n",
       "\n",
       "                             narration  \\\n",
       "0  ['plummets down', 'he vaul7 front']   \n",
       "1                                   []   \n",
       "2                                   []   \n",
       "3                                   []   \n",
       "4                                   []   \n",
       "\n",
       "                                                text  \\\n",
       "0  ['oops ! cheap twine or must have gained weigh...   \n",
       "1                       [' just a minute , you ...']   \n",
       "2  [\"they think they bungled and are going to rep...   \n",
       "3                                          ['owuch']   \n",
       "4  [\"look nightmare ! o he ' s gone through w the...   \n",
       "\n",
       "                                          text_clean  \\\n",
       "0  ['ops   ! cheap twine or must have gained weig...   \n",
       "1            ['just a minute , you   .   .   .   .']   \n",
       "2  ['they think they bungled and are going to rep...   \n",
       "3                                        ['wow   .']   \n",
       "4  ['look nightmare   ! he is gone through the we...   \n",
       "\n",
       "                                       emotion_list            one_hot_labels  \n",
       "0                               ['Sad', 'Surprise']  [0, 0, 0, 0, 1, 1, 0, 0]  \n",
       "1  ['Angry', 'Disgust', 'Fear', 'Happy', 'Neutral']  [1, 1, 1, 1, 0, 0, 1, 0]  \n",
       "2            ['Angry', 'Disgust', 'Sad', 'Neutral']  [1, 1, 0, 0, 1, 0, 1, 0]  \n",
       "3                  ['Angry', 'Surprise', 'Neutral']  [1, 0, 0, 0, 0, 1, 1, 0]  \n",
       "4                              ['Angry', 'Neutral']  [1, 0, 0, 0, 0, 0, 1, 0]  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_df = validation_df[~validation_df[validation_label_cols].eq(-1).any(axis=1)] #remove irrelevant rows/ocr_texts with -1 values\n",
    "validation_df['one_hot_labels'] = list(validation_df[validation_label_cols].values)\n",
    "validation_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "486"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(validation_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(486, 3, 224, 224)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_img_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "1a41OmU2i7qp"
   },
   "outputs": [],
   "source": [
    "# Gathering input data\n",
    "validation_labels = list(validation_df.one_hot_labels.values)\n",
    "validation_ocr_texts = list(validation_df.text_clean.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "amySMO8EQzf2",
    "outputId": "05a48e2e-8b6d-4000-a5e7-cbc9c23b7b17"
   },
   "outputs": [],
   "source": [
    "# Encoding input data\n",
    "validation_encodings = tokenizer.batch_encode_plus(validation_ocr_texts,max_length=max_length,pad_to_max_length=True)\n",
    "validation_input_ids = validation_encodings['input_ids']\n",
    "# validation_token_type_ids = validation_encodings['token_type_ids']\n",
    "validation_attention_masks = validation_encodings['attention_mask']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "hqOfi9fkRaRN"
   },
   "outputs": [],
   "source": [
    "# Make tensors out of data\n",
    "validation_inputs = torch.tensor(validation_input_ids)\n",
    "validation_labels = torch.tensor(validation_labels)\n",
    "validation_masks = torch.tensor(validation_attention_masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 391
    },
    "id": "G5Q7hC4GFOLJ",
    "outputId": "5cb49a39-b967-43f8-9cea-c97d027e194e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Null values:  False\n",
      "Same columns between train and test:  True\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>image_id</th>\n",
       "      <th>Angry</th>\n",
       "      <th>Disgust</th>\n",
       "      <th>Fear</th>\n",
       "      <th>Happy</th>\n",
       "      <th>Sad</th>\n",
       "      <th>Surprise</th>\n",
       "      <th>Neutral</th>\n",
       "      <th>Others</th>\n",
       "      <th>dialog</th>\n",
       "      <th>narration</th>\n",
       "      <th>text</th>\n",
       "      <th>text_clean</th>\n",
       "      <th>emotion_list</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>4184.0</td>\n",
       "      <td>3812_3_3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>['or this what kind of reputation are these pi...</td>\n",
       "      <td>[\"tha day prog ahranean the recovery ou thats ...</td>\n",
       "      <td>['or this what kind of reputation are these pi...</td>\n",
       "      <td>['or this what kind of reputation are these pi...</td>\n",
       "      <td>['Angry', 'Disgust', 'Fear', 'Neutral']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>132.0</td>\n",
       "      <td>1088_28_3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[\"he ' s not telling all he knows do you think...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[\"he ' s not telling all he knows do you think...</td>\n",
       "      <td>['he is not telling all he knows , do you thin...</td>\n",
       "      <td>['Angry', 'Fear', 'Neutral']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3543.0</td>\n",
       "      <td>479_14_0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[\"you big stupid why don ' t you watch where y...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[\"you big stupid why don ' t you watch where y...</td>\n",
       "      <td>['you big stupid why do not you watch where yo...</td>\n",
       "      <td>['Angry', 'Neutral']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4692.0</td>\n",
       "      <td>859_24_1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[\"fight it out with him it ' s the gallows if ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[\"fight it out with him it ' s the gallows if ...</td>\n",
       "      <td>['fight it out with him it is the gallows if h...</td>\n",
       "      <td>['Angry', 'Disgust', 'Fear', 'Surprise', 'Neut...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>4762.0</td>\n",
       "      <td>2260_47_8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>['this way to the roof']</td>\n",
       "      <td>['the fleeing boxer and photographer']</td>\n",
       "      <td>['this way to the roof', 'the fleeing boxer an...</td>\n",
       "      <td>['this way to the roof   .', 'the fleeing boxe...</td>\n",
       "      <td>['Fear', 'Happy', 'Neutral']</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id   image_id  Angry  Disgust  Fear  Happy  Sad  Surprise  Neutral  \\\n",
       "0  4184.0   3812_3_3      1        1     1      0    0         0        1   \n",
       "1   132.0  1088_28_3      1        0     1      0    0         0        1   \n",
       "2  3543.0   479_14_0      1        0     0      0    0         0        1   \n",
       "3  4692.0   859_24_1      1        1     1      0    0         1        1   \n",
       "4  4762.0  2260_47_8      0        0     1      1    0         0        1   \n",
       "\n",
       "   Others                                             dialog  \\\n",
       "0       0  ['or this what kind of reputation are these pi...   \n",
       "1       0  [\"he ' s not telling all he knows do you think...   \n",
       "2       0  [\"you big stupid why don ' t you watch where y...   \n",
       "3       0  [\"fight it out with him it ' s the gallows if ...   \n",
       "4       0                           ['this way to the roof']   \n",
       "\n",
       "                                           narration  \\\n",
       "0  [\"tha day prog ahranean the recovery ou thats ...   \n",
       "1                                                 []   \n",
       "2                                                 []   \n",
       "3                                                 []   \n",
       "4             ['the fleeing boxer and photographer']   \n",
       "\n",
       "                                                text  \\\n",
       "0  ['or this what kind of reputation are these pi...   \n",
       "1  [\"he ' s not telling all he knows do you think...   \n",
       "2  [\"you big stupid why don ' t you watch where y...   \n",
       "3  [\"fight it out with him it ' s the gallows if ...   \n",
       "4  ['this way to the roof', 'the fleeing boxer an...   \n",
       "\n",
       "                                          text_clean  \\\n",
       "0  ['or this what kind of reputation are these pi...   \n",
       "1  ['he is not telling all he knows , do you thin...   \n",
       "2  ['you big stupid why do not you watch where yo...   \n",
       "3  ['fight it out with him it is the gallows if h...   \n",
       "4  ['this way to the roof   .', 'the fleeing boxe...   \n",
       "\n",
       "                                        emotion_list  \n",
       "0            ['Angry', 'Disgust', 'Fear', 'Neutral']  \n",
       "1                       ['Angry', 'Fear', 'Neutral']  \n",
       "2                               ['Angry', 'Neutral']  \n",
       "3  ['Angry', 'Disgust', 'Fear', 'Surprise', 'Neut...  \n",
       "4                       ['Fear', 'Happy', 'Neutral']  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = pd.read_csv('../data/public_train/test_data.csv')\n",
    "# test_labels_df = pd.read_csv('test_labels.csv')\n",
    "# test_df = test_df.merge(test_labels_df, on='id', how='left')\n",
    "test_label_cols = list(test_df.columns[2:10])\n",
    "print('Null values: ', test_df.isnull().values.any()) #should not be any null sentences or labels\n",
    "print('Same columns between train and test: ', label_cols == test_label_cols) #columns should be the same\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 391
    },
    "id": "77rjCrMGpYxz",
    "outputId": "d9682639-991e-472c-d07f-33336b85f589"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>image_id</th>\n",
       "      <th>Angry</th>\n",
       "      <th>Disgust</th>\n",
       "      <th>Fear</th>\n",
       "      <th>Happy</th>\n",
       "      <th>Sad</th>\n",
       "      <th>Surprise</th>\n",
       "      <th>Neutral</th>\n",
       "      <th>Others</th>\n",
       "      <th>dialog</th>\n",
       "      <th>narration</th>\n",
       "      <th>text</th>\n",
       "      <th>text_clean</th>\n",
       "      <th>emotion_list</th>\n",
       "      <th>one_hot_labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>4184.0</td>\n",
       "      <td>3812_3_3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>['or this what kind of reputation are these pi...</td>\n",
       "      <td>[\"tha day prog ahranean the recovery ou thats ...</td>\n",
       "      <td>['or this what kind of reputation are these pi...</td>\n",
       "      <td>['or this what kind of reputation are these pi...</td>\n",
       "      <td>['Angry', 'Disgust', 'Fear', 'Neutral']</td>\n",
       "      <td>[1, 1, 1, 0, 0, 0, 1, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>132.0</td>\n",
       "      <td>1088_28_3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[\"he ' s not telling all he knows do you think...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[\"he ' s not telling all he knows do you think...</td>\n",
       "      <td>['he is not telling all he knows , do you thin...</td>\n",
       "      <td>['Angry', 'Fear', 'Neutral']</td>\n",
       "      <td>[1, 0, 1, 0, 0, 0, 1, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3543.0</td>\n",
       "      <td>479_14_0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[\"you big stupid why don ' t you watch where y...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[\"you big stupid why don ' t you watch where y...</td>\n",
       "      <td>['you big stupid why do not you watch where yo...</td>\n",
       "      <td>['Angry', 'Neutral']</td>\n",
       "      <td>[1, 0, 0, 0, 0, 0, 1, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4692.0</td>\n",
       "      <td>859_24_1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[\"fight it out with him it ' s the gallows if ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[\"fight it out with him it ' s the gallows if ...</td>\n",
       "      <td>['fight it out with him it is the gallows if h...</td>\n",
       "      <td>['Angry', 'Disgust', 'Fear', 'Surprise', 'Neut...</td>\n",
       "      <td>[1, 1, 1, 0, 0, 1, 1, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>4762.0</td>\n",
       "      <td>2260_47_8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>['this way to the roof']</td>\n",
       "      <td>['the fleeing boxer and photographer']</td>\n",
       "      <td>['this way to the roof', 'the fleeing boxer an...</td>\n",
       "      <td>['this way to the roof   .', 'the fleeing boxe...</td>\n",
       "      <td>['Fear', 'Happy', 'Neutral']</td>\n",
       "      <td>[0, 0, 1, 1, 0, 0, 1, 0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id   image_id  Angry  Disgust  Fear  Happy  Sad  Surprise  Neutral  \\\n",
       "0  4184.0   3812_3_3      1        1     1      0    0         0        1   \n",
       "1   132.0  1088_28_3      1        0     1      0    0         0        1   \n",
       "2  3543.0   479_14_0      1        0     0      0    0         0        1   \n",
       "3  4692.0   859_24_1      1        1     1      0    0         1        1   \n",
       "4  4762.0  2260_47_8      0        0     1      1    0         0        1   \n",
       "\n",
       "   Others                                             dialog  \\\n",
       "0       0  ['or this what kind of reputation are these pi...   \n",
       "1       0  [\"he ' s not telling all he knows do you think...   \n",
       "2       0  [\"you big stupid why don ' t you watch where y...   \n",
       "3       0  [\"fight it out with him it ' s the gallows if ...   \n",
       "4       0                           ['this way to the roof']   \n",
       "\n",
       "                                           narration  \\\n",
       "0  [\"tha day prog ahranean the recovery ou thats ...   \n",
       "1                                                 []   \n",
       "2                                                 []   \n",
       "3                                                 []   \n",
       "4             ['the fleeing boxer and photographer']   \n",
       "\n",
       "                                                text  \\\n",
       "0  ['or this what kind of reputation are these pi...   \n",
       "1  [\"he ' s not telling all he knows do you think...   \n",
       "2  [\"you big stupid why don ' t you watch where y...   \n",
       "3  [\"fight it out with him it ' s the gallows if ...   \n",
       "4  ['this way to the roof', 'the fleeing boxer an...   \n",
       "\n",
       "                                          text_clean  \\\n",
       "0  ['or this what kind of reputation are these pi...   \n",
       "1  ['he is not telling all he knows , do you thin...   \n",
       "2  ['you big stupid why do not you watch where yo...   \n",
       "3  ['fight it out with him it is the gallows if h...   \n",
       "4  ['this way to the roof   .', 'the fleeing boxe...   \n",
       "\n",
       "                                        emotion_list            one_hot_labels  \n",
       "0            ['Angry', 'Disgust', 'Fear', 'Neutral']  [1, 1, 1, 0, 0, 0, 1, 0]  \n",
       "1                       ['Angry', 'Fear', 'Neutral']  [1, 0, 1, 0, 0, 0, 1, 0]  \n",
       "2                               ['Angry', 'Neutral']  [1, 0, 0, 0, 0, 0, 1, 0]  \n",
       "3  ['Angry', 'Disgust', 'Fear', 'Surprise', 'Neut...  [1, 1, 1, 0, 0, 1, 1, 0]  \n",
       "4                       ['Fear', 'Happy', 'Neutral']  [0, 0, 1, 1, 0, 0, 1, 0]  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = test_df[~test_df[test_label_cols].eq(-1).any(axis=1)] #remove irrelevant rows/ocr_texts with -1 values\n",
    "test_df['one_hot_labels'] = list(test_df[test_label_cols].values)\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "1a41OmU2i7qp"
   },
   "outputs": [],
   "source": [
    "# Gathering input data\n",
    "test_labels = list(test_df.one_hot_labels.values)\n",
    "test_ocr_texts = list(test_df.text_clean.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "amySMO8EQzf2",
    "outputId": "05a48e2e-8b6d-4000-a5e7-cbc9c23b7b17"
   },
   "outputs": [],
   "source": [
    "# Encoding input data\n",
    "test_encodings = tokenizer.batch_encode_plus(test_ocr_texts,max_length=max_length,pad_to_max_length=True)\n",
    "test_input_ids = test_encodings['input_ids']\n",
    "# test_token_type_ids = test_encodings['token_type_ids']\n",
    "test_attention_masks = test_encodings['attention_mask']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "hqOfi9fkRaRN"
   },
   "outputs": [],
   "source": [
    "# Make tensors out of data\n",
    "test_inputs = torch.tensor(test_input_ids)\n",
    "test_labels = torch.tensor(test_labels)\n",
    "test_masks = torch.tensor(test_attention_masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "273 273\n",
      "31 31\n",
      "76 76\n"
     ]
    }
   ],
   "source": [
    "text_train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
    "img_train_data = TensorDataset(torch.from_numpy(X_img_train), train_labels)\n",
    "\n",
    "text_val_data = TensorDataset(validation_inputs, validation_masks, validation_labels)\n",
    "img_val_data = TensorDataset(torch.from_numpy(X_img_val), validation_labels)\n",
    "\n",
    "text_test_data = TensorDataset(test_inputs, test_masks, test_labels)\n",
    "img_test_data = TensorDataset(torch.from_numpy(X_img_test), test_labels)\n",
    "\n",
    "batch_size = 16\n",
    "\n",
    "text_train_loader = DataLoader(text_train_data, batch_size=batch_size)\n",
    "img_train_loader = DataLoader(img_train_data, batch_size=batch_size)\n",
    "\n",
    "text_val_loader = DataLoader(text_val_data, batch_size=batch_size)\n",
    "img_val_loader = DataLoader(img_val_data, batch_size=batch_size)\n",
    "\n",
    "text_test_loader = DataLoader(text_test_data, batch_size=batch_size)\n",
    "img_test_loader = DataLoader(img_test_data, batch_size=batch_size)\n",
    "\n",
    "print(len(text_train_loader), len(img_train_loader))\n",
    "print(len(text_val_loader), len(img_val_loader))\n",
    "print(len(text_test_loader), len(img_test_loader))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ncGteBuSFuZM"
   },
   "source": [
    "## Load Model & Set Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN_BERT(nn.Module):\n",
    "  def __init__(self):\n",
    "    super(CNN_BERT, self).__init__()\n",
    "\n",
    "    # BERT for the text overview\n",
    "    self.text_model = RobertaModel.from_pretrained('roberta-base')\n",
    "    self.dropout = nn.Dropout(0.3)\n",
    "    self.text_fc = nn.Linear(768,32)\n",
    "\n",
    "    # CNN for the posters\n",
    "    self.effnet = EfficientNet.from_pretrained('efficientnet-b2')\n",
    "    self.effnet_fc = nn.Linear(1000, 32)\n",
    "    self.n_out = 8\n",
    "#     self.concat_dropout = nn.Dropout(0.1)\n",
    "    self.output_fc = nn.Linear(64, self.n_out)\n",
    "\n",
    "\n",
    "  def forward(self, input_ids, attention_mask, cnn_inp):\n",
    "    text_outputs = self.text_model(input_ids, attention_mask)\n",
    "#     text_outputs = text_outputs['last_hidden_state']\n",
    "    text_outputs = text_outputs[0][:, 0, :]\n",
    "    text_outputs = self.dropout(text_outputs)\n",
    "    text_outputs = self.text_fc(text_outputs)\n",
    "    \n",
    "    x = self.effnet(cnn_inp)\n",
    "    x = self.dropout(x)\n",
    "    cnn_out = F.relu(self.effnet_fc(x))\n",
    "    combined_inp = torch.cat((cnn_out, text_outputs), 1)\n",
    "#     out = torch.sigmoid(self.output_fc(self.concat_dropout(combined_inp)))\n",
    "    out = torch.sigmoid(self.output_fc(combined_inp))\n",
    "\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained weights for efficientnet-b2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CNN_BERT(\n",
       "  (text_model): RobertaModel(\n",
       "    (embeddings): RobertaEmbeddings(\n",
       "      (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
       "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "      (token_type_embeddings): Embedding(1, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): RobertaEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): RobertaPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.3, inplace=False)\n",
       "  (text_fc): Linear(in_features=768, out_features=32, bias=True)\n",
       "  (effnet): EfficientNet(\n",
       "    (_conv_stem): Conv2dStaticSamePadding(\n",
       "      3, 32, kernel_size=(3, 3), stride=(2, 2), bias=False\n",
       "      (static_padding): ZeroPad2d(padding=(0, 1, 0, 1), value=0.0)\n",
       "    )\n",
       "    (_bn0): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    (_blocks): ModuleList(\n",
       "      (0): MBConvBlock(\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          32, 32, kernel_size=(3, 3), stride=[1, 1], groups=32, bias=False\n",
       "          (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          32, 8, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          8, 32, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(16, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_swish): MemoryEfficientSwish()\n",
       "      )\n",
       "      (1): MBConvBlock(\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          16, 16, kernel_size=(3, 3), stride=(1, 1), groups=16, bias=False\n",
       "          (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(16, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          16, 4, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          4, 16, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          16, 16, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(16, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_swish): MemoryEfficientSwish()\n",
       "      )\n",
       "      (2): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          96, 96, kernel_size=(3, 3), stride=[2, 2], groups=96, bias=False\n",
       "          (static_padding): ZeroPad2d(padding=(0, 1, 0, 1), value=0.0)\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          96, 4, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          4, 96, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_swish): MemoryEfficientSwish()\n",
       "      )\n",
       "      (3): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          144, 144, kernel_size=(3, 3), stride=(1, 1), groups=144, bias=False\n",
       "          (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          144, 6, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          6, 144, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_swish): MemoryEfficientSwish()\n",
       "      )\n",
       "      (4): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          144, 144, kernel_size=(3, 3), stride=(1, 1), groups=144, bias=False\n",
       "          (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          144, 6, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          6, 144, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_swish): MemoryEfficientSwish()\n",
       "      )\n",
       "      (5): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          144, 144, kernel_size=(5, 5), stride=[2, 2], groups=144, bias=False\n",
       "          (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          144, 6, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          6, 144, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          144, 48, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(48, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_swish): MemoryEfficientSwish()\n",
       "      )\n",
       "      (6): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          288, 288, kernel_size=(5, 5), stride=(1, 1), groups=288, bias=False\n",
       "          (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          288, 12, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          12, 288, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(48, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_swish): MemoryEfficientSwish()\n",
       "      )\n",
       "      (7): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          288, 288, kernel_size=(5, 5), stride=(1, 1), groups=288, bias=False\n",
       "          (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          288, 12, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          12, 288, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(48, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_swish): MemoryEfficientSwish()\n",
       "      )\n",
       "      (8): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          288, 288, kernel_size=(3, 3), stride=[2, 2], groups=288, bias=False\n",
       "          (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          288, 12, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          12, 288, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          288, 88, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(88, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_swish): MemoryEfficientSwish()\n",
       "      )\n",
       "      (9): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(528, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          528, 528, kernel_size=(3, 3), stride=(1, 1), groups=528, bias=False\n",
       "          (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(528, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          528, 22, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          22, 528, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(88, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_swish): MemoryEfficientSwish()\n",
       "      )\n",
       "      (10): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(528, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          528, 528, kernel_size=(3, 3), stride=(1, 1), groups=528, bias=False\n",
       "          (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(528, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          528, 22, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          22, 528, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(88, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_swish): MemoryEfficientSwish()\n",
       "      )\n",
       "      (11): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(528, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          528, 528, kernel_size=(3, 3), stride=(1, 1), groups=528, bias=False\n",
       "          (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(528, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          528, 22, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          22, 528, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(88, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_swish): MemoryEfficientSwish()\n",
       "      )\n",
       "      (12): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(528, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          528, 528, kernel_size=(5, 5), stride=[1, 1], groups=528, bias=False\n",
       "          (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(528, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          528, 22, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          22, 528, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          528, 120, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(120, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_swish): MemoryEfficientSwish()\n",
       "      )\n",
       "      (13): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          120, 720, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(720, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          720, 720, kernel_size=(5, 5), stride=(1, 1), groups=720, bias=False\n",
       "          (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(720, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          720, 30, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          30, 720, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          720, 120, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(120, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_swish): MemoryEfficientSwish()\n",
       "      )\n",
       "      (14): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          120, 720, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(720, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          720, 720, kernel_size=(5, 5), stride=(1, 1), groups=720, bias=False\n",
       "          (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(720, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          720, 30, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          30, 720, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          720, 120, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(120, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_swish): MemoryEfficientSwish()\n",
       "      )\n",
       "      (15): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          120, 720, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(720, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          720, 720, kernel_size=(5, 5), stride=(1, 1), groups=720, bias=False\n",
       "          (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(720, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          720, 30, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          30, 720, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          720, 120, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(120, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_swish): MemoryEfficientSwish()\n",
       "      )\n",
       "      (16): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          120, 720, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(720, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          720, 720, kernel_size=(5, 5), stride=[2, 2], groups=720, bias=False\n",
       "          (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(720, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          720, 30, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          30, 720, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          720, 208, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(208, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_swish): MemoryEfficientSwish()\n",
       "      )\n",
       "      (17): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          208, 1248, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(1248, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          1248, 1248, kernel_size=(5, 5), stride=(1, 1), groups=1248, bias=False\n",
       "          (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(1248, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          1248, 52, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          52, 1248, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          1248, 208, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(208, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_swish): MemoryEfficientSwish()\n",
       "      )\n",
       "      (18): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          208, 1248, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(1248, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          1248, 1248, kernel_size=(5, 5), stride=(1, 1), groups=1248, bias=False\n",
       "          (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(1248, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          1248, 52, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          52, 1248, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          1248, 208, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(208, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_swish): MemoryEfficientSwish()\n",
       "      )\n",
       "      (19): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          208, 1248, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(1248, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          1248, 1248, kernel_size=(5, 5), stride=(1, 1), groups=1248, bias=False\n",
       "          (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(1248, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          1248, 52, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          52, 1248, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          1248, 208, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(208, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_swish): MemoryEfficientSwish()\n",
       "      )\n",
       "      (20): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          208, 1248, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(1248, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          1248, 1248, kernel_size=(5, 5), stride=(1, 1), groups=1248, bias=False\n",
       "          (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(1248, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          1248, 52, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          52, 1248, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          1248, 208, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(208, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_swish): MemoryEfficientSwish()\n",
       "      )\n",
       "      (21): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          208, 1248, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(1248, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          1248, 1248, kernel_size=(3, 3), stride=[1, 1], groups=1248, bias=False\n",
       "          (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(1248, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          1248, 52, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          52, 1248, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          1248, 352, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(352, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_swish): MemoryEfficientSwish()\n",
       "      )\n",
       "      (22): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          352, 2112, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(2112, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          2112, 2112, kernel_size=(3, 3), stride=(1, 1), groups=2112, bias=False\n",
       "          (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(2112, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          2112, 88, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          88, 2112, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          2112, 352, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(352, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_swish): MemoryEfficientSwish()\n",
       "      )\n",
       "    )\n",
       "    (_conv_head): Conv2dStaticSamePadding(\n",
       "      352, 1408, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "      (static_padding): Identity()\n",
       "    )\n",
       "    (_bn1): BatchNorm2d(1408, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    (_avg_pooling): AdaptiveAvgPool2d(output_size=1)\n",
       "    (_dropout): Dropout(p=0.3, inplace=False)\n",
       "    (_fc): Linear(in_features=1408, out_features=1000, bias=True)\n",
       "    (_swish): MemoryEfficientSwish()\n",
       "  )\n",
       "  (effnet_fc): Linear(in_features=1000, out_features=32, bias=True)\n",
       "  (output_fc): Linear(in_features=64, out_features=8, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = CNN_BERT()\n",
    "model.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jGE4gv9qfhRG"
   },
   "source": [
    "Setting custom optimization parameters for the AdamW optimizer https://huggingface.co/transformers/main_classes/optimizer_schedules.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "GsV8zwWYnIT9"
   },
   "outputs": [],
   "source": [
    "# setting custom optimization parameters. You may implement a scheduler here as well.\n",
    "param_optimizer = list(model.named_parameters())\n",
    "no_decay = ['bias', 'gamma', 'beta']\n",
    "optimizer_grouped_parameters = [\n",
    "    {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)],\n",
    "     'weight_decay_rate': 0.01},\n",
    "    {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)],\n",
    "     'weight_decay_rate': 0.01}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "506"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(param_optimizer) #366"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimizer_grouped_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "id": "aOomZIEIoHOL"
   },
   "outputs": [],
   "source": [
    "optimizer = AdamW(optimizer_grouped_parameters,lr=2e-5,correct_bias=True)\n",
    "# optimizer = AdamW(model.parameters(),lr=1e-5,weight_decay=1e-2)  # Default optimization\n",
    "# scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr=0.1, steps_per_epoch=len(text_train_loader), epochs=5,anneal_strategy='linear')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JRQQZ8zIFzLW"
   },
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uDLZmEC_oKo3",
    "outputId": "99ab5322-abdb-4d21-d256-16e9cfc41256",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:   0%|          | 0/6 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.5830012733464712\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  17%|█▋        | 1/6 [08:37<43:08, 517.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss: 0.5767187053157438\n",
      "F1 Validation Accuracy:  19.4297565619797\n",
      "Flat Validation Accuracy:  4.938271604938271\n",
      "ROC AUC Score:  51.909010292892276\n",
      "Train loss: 0.554130093518631\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  33%|███▎      | 2/6 [16:25<32:33, 488.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss: 0.5637662747213917\n",
      "F1 Validation Accuracy:  31.199832368895947\n",
      "Flat Validation Accuracy:  8.641975308641975\n",
      "ROC AUC Score:  55.1909624976472\n",
      "Train loss: 0.5291926261487898\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  50%|█████     | 3/6 [24:07<23:49, 476.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss: 0.5635578795786826\n",
      "F1 Validation Accuracy:  33.36139870853949\n",
      "Flat Validation Accuracy:  9.465020576131687\n",
      "ROC AUC Score:  55.63976919743288\n",
      "Train loss: 0.49686577195649617\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  67%|██████▋   | 4/6 [31:48<15:40, 470.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss: 0.5761572064891938\n",
      "F1 Validation Accuracy:  35.920994789954655\n",
      "Flat Validation Accuracy:  9.053497942386832\n",
      "ROC AUC Score:  56.4919075159342\n",
      "Train loss: 0.4610640043085748\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  83%|████████▎ | 5/6 [40:42<08:13, 493.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss: 0.5902829170227051\n",
      "F1 Validation Accuracy:  36.3914379802183\n",
      "Flat Validation Accuracy:  8.024691358024691\n",
      "ROC AUC Score:  56.45966299829996\n",
      "Train loss: 0.4182310619633713\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 100%|██████████| 6/6 [49:03<00:00, 490.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss: 0.6089247032519309\n",
      "F1 Validation Accuracy:  39.327157884659755\n",
      "Flat Validation Accuracy:  7.4074074074074066\n",
      "ROC AUC Score:  57.44911751778554\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Store our loss and accuracy for plotting\n",
    "train_loss_set = []\n",
    "val_loss_set = []\n",
    "\n",
    "# Number of training epochs (authors recommend between 2 and 4)\n",
    "epochs = 6\n",
    "\n",
    "# trange is a tqdm wrapper around the normal python range\n",
    "for _ in trange(epochs, desc=\"Epoch\"):\n",
    "\n",
    "  # Training\n",
    "  \n",
    "  # Set our model to training mode (as opposed to evaluation mode)\n",
    "  model.train()\n",
    "\n",
    "  # Tracking variables\n",
    "  tr_loss = 0 #running loss\n",
    "  val_loss = 0 #running loss\n",
    "  nb_tr_examples, nb_tr_steps = 0, 0\n",
    "  nb_val_steps = 0\n",
    "  \n",
    "  # Train the data for one epoch\n",
    "  for text_batch, img_batch in zip(text_train_loader,img_train_loader):\n",
    "    # Add batch to GPU\n",
    "    text_batch = tuple(t.to(device) for t in text_batch)\n",
    "    img_batch = tuple(t.to(device) for t in img_batch)\n",
    "    # Unpack the inputs from our dataloader\n",
    "    b_input_ids, b_input_mask, b_labels = text_batch\n",
    "    cnn_inp, cnn_labels = img_batch\n",
    "    # Clear out the gradients (by default they accumulate)\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "\n",
    "    # Forward pass for multilabel classification\n",
    "    outputs = model(b_input_ids, b_input_mask,cnn_inp)\n",
    "#     loss_func = BCEWithLogitsLoss()\n",
    "    loss_func = BCELoss()\n",
    "#     loss = loss_func(outputs.view(-1,num_labels),b_labels.type_as(outputs).view(-1,num_labels)) #convert labels to float for calculation\n",
    "    loss = loss_func(outputs.squeeze(), b_labels.float())\n",
    "    # loss_func = BCELoss() \n",
    "    # loss = loss_func(torch.sigmoid(logits.view(-1,num_labels)),b_labels.type_as(logits).view(-1,num_labels)) #convert labels to float for calculation\n",
    "    train_loss_set.append(loss.item())    \n",
    "\n",
    "    # Backward pass\n",
    "    loss.backward()\n",
    "    # Update parameters and take a step using the computed gradient\n",
    "    optimizer.step()\n",
    "#     scheduler.step()\n",
    "    # Update tracking variables\n",
    "    tr_loss += loss.item()\n",
    "    nb_tr_examples += b_input_ids.size(0)\n",
    "    nb_tr_steps += 1\n",
    "\n",
    "  print(\"Train loss: {}\".format(tr_loss/nb_tr_steps))\n",
    "\n",
    "###############################################################################\n",
    "\n",
    "  # Validation\n",
    "\n",
    "  # Put model in evaluation mode to evaluate loss on the validation set\n",
    "  model.eval()\n",
    "\n",
    "  # Variables to gather full output\n",
    "  logit_preds,true_labels,pred_labels,tokenized_texts = [],[],[],[]\n",
    "\n",
    "  # Predict\n",
    "  for text_batch, img_batch in zip(text_val_loader,img_val_loader):\n",
    "    # Unpack the inputs from our dataloader\n",
    "    text_batch = tuple(t.to(device) for t in text_batch)\n",
    "    img_batch = tuple(t.to(device) for t in img_batch)\n",
    "    b_input_ids, b_input_mask, b_labels = text_batch\n",
    "    cnn_inp, cnn_labels = img_batch\n",
    "    with torch.no_grad():\n",
    "      # Forward pass\n",
    "      outs = model(b_input_ids, b_input_mask,cnn_inp)\n",
    "      \n",
    "      v_loss = loss_func(outs.squeeze(), b_labels.float())\n",
    "#       v_loss = loss_func(outs.view(-1,num_labels),b_labels.type_as(outs).view(-1,num_labels)) #convert labels to float for calculation\n",
    "      val_loss_set.append(v_loss.item())  \n",
    "      val_loss += v_loss.item()\n",
    "      pred_label = outs.squeeze()\n",
    "\n",
    "#       b_logit_pred = b_logit_pred.detach().cpu().numpy()\n",
    "      pred_label = pred_label.to('cpu').numpy()\n",
    "      b_labels = b_labels.to('cpu').numpy()\n",
    "\n",
    "    tokenized_texts.append(b_input_ids)\n",
    "#     logit_preds.append(b_logit_pred)\n",
    "    true_labels.append(b_labels)\n",
    "    pred_labels.append(pred_label)\n",
    "    nb_val_steps += 1\n",
    "\n",
    "  print(\"Val loss: {}\".format(val_loss/nb_val_steps))\n",
    "  # Flatten outputs\n",
    "  pred_labels = [item for sublist in pred_labels for item in sublist]\n",
    "  true_labels = [item for sublist in true_labels for item in sublist]\n",
    "  \n",
    "  # Calculate Accuracy\n",
    "  threshold = 0.50\n",
    "  pred_bools = [pl>threshold for pl in pred_labels]\n",
    "  true_bools = [tl==1 for tl in true_labels]\n",
    "  val_f1_accuracy = f1_score(true_bools,pred_bools,average='macro')*100\n",
    "  val_flat_accuracy = accuracy_score(true_bools, pred_bools)*100\n",
    "  val_roc_score = roc_auc_score(true_bools, pred_bools,average='macro')*100\n",
    "\n",
    "  print('F1 Validation Accuracy: ', val_f1_accuracy)\n",
    "  print('Flat Validation Accuracy: ', val_flat_accuracy)\n",
    "  print('ROC AUC Score: ', val_roc_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "id": "aiBeiBSRoOuz"
   },
   "outputs": [],
   "source": [
    "# torch.save(model.state_dict(), 'roberta_effnet_model_1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = CNN_BERT()\n",
    "# model.load_state_dict(torch.load('roberta_effnet_model_1'))\n",
    "# model.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_7dd2GE3F4yK"
   },
   "source": [
    "## Load and Preprocess Test Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PFTWxCA_GBau"
   },
   "source": [
    "## Prediction and Metics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "id": "NPvrL6OFSQvf"
   },
   "outputs": [],
   "source": [
    "# Test\n",
    "\n",
    "# Put model in evaluation mode to evaluate loss on the validation set\n",
    "model.eval()\n",
    "\n",
    "#track variables\n",
    "logit_preds,true_labels,pred_labels,tokenized_texts = [],[],[],[]\n",
    "\n",
    "# Predict\n",
    "for text_batch, img_batch in zip(text_test_loader,img_test_loader):\n",
    "  text_batch = tuple(t.to(device) for t in text_batch)\n",
    "  img_batch = tuple(t.to(device) for t in img_batch)\n",
    "  b_input_ids, b_input_mask, b_labels = text_batch\n",
    "  cnn_inp, cnn_labels = img_batch\n",
    "    \n",
    "  with torch.no_grad():\n",
    "    # Forward pass\n",
    "    outs = model(b_input_ids, b_input_mask,cnn_inp)\n",
    "    pred_label = outs.squeeze()\n",
    "    pred_label = pred_label.to('cpu').numpy()\n",
    "    b_labels = b_labels.to('cpu').numpy()\n",
    "\n",
    "  tokenized_texts.append(b_input_ids)\n",
    "#   logit_preds.append(b_logit_pred)\n",
    "  true_labels.append(b_labels)\n",
    "  pred_labels.append(pred_label)\n",
    "\n",
    "# Flatten outputs\n",
    "tokenized_texts = [item for sublist in tokenized_texts for item in sublist]\n",
    "pred_labels = [item for sublist in pred_labels for item in sublist]\n",
    "true_labels = [item for sublist in true_labels for item in sublist]\n",
    "# Converting flattened binary values to boolean values\n",
    "true_bools = [tl==1 for tl in true_labels]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bQeGWqeMzAoZ"
   },
   "source": [
    "We need to threshold our sigmoid function outputs which range from [0, 1]. Below I use 0.50 as a threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BZcZUcYOxxmM",
    "outputId": "d2b99364-f334-421e-9009-f82c91cf9dd5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test F1 Accuracy:  0.5262985417008028\n",
      "Test ROC AUC Score:  0.5659047533037628\n",
      "Test Flat Accuracy:  0.06430338004946413 \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Angry       0.56      0.39      0.46       474\n",
      "     Disgust       0.52      0.38      0.44       450\n",
      "        Fear       0.62      0.27      0.38       444\n",
      "       Happy       0.58      0.66      0.61       516\n",
      "         Sad       0.67      0.01      0.02       206\n",
      "    Surprise       0.37      0.30      0.33       412\n",
      "     Neutral       0.70      0.83      0.76       797\n",
      "      Others       0.50      0.01      0.03        75\n",
      "\n",
      "   micro avg       0.59      0.48      0.53      3374\n",
      "   macro avg       0.56      0.36      0.38      3374\n",
      "weighted avg       0.58      0.48      0.49      3374\n",
      " samples avg       0.61      0.51      0.52      3374\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shwetkm/anaconda3/envs/ml/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/shwetkm/anaconda3/envs/ml/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "pred_bools = [pl>0.50 for pl in pred_labels] #boolean output after thresholding\n",
    "\n",
    "# Print and save classification report\n",
    "print('Test F1 Accuracy: ', f1_score(true_bools, pred_bools,average='micro'))\n",
    "print('Test ROC AUC Score: ', roc_auc_score(true_bools, pred_bools,average='macro'))\n",
    "print('Test Flat Accuracy: ', accuracy_score(true_bools, pred_bools),'\\n')\n",
    "clf_report = classification_report(true_bools,pred_bools,target_names=test_label_cols)\n",
    "pickle.dump(clf_report, open('classification_report.txt','wb')) #save report\n",
    "print(clf_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5rLqrHK87eir"
   },
   "source": [
    "## Output Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CJBkRdGN1hzx",
    "outputId": "857214e2-c4c1-48bf-9517-f664bafcfd1e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 'Angry', 1: 'Disgust', 2: 'Fear', 3: 'Happy', 4: 'Sad', 5: 'Surprise', 6: 'Neutral', 7: 'Others'}\n"
     ]
    }
   ],
   "source": [
    "idx2label = dict(zip(range(8),label_cols))\n",
    "print(idx2label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "id": "QZUglV_A4BF_"
   },
   "outputs": [],
   "source": [
    "# Getting indices of where boolean one hot vector true_bools is True so we can use idx2label to gather label names\n",
    "true_label_idxs, pred_label_idxs=[],[]\n",
    "for vals in true_bools:\n",
    "  true_label_idxs.append(np.where(vals)[0].flatten().tolist())\n",
    "for vals in pred_bools:\n",
    "  pred_label_idxs.append(np.where(vals)[0].flatten().tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "id": "OOGhXM3R4a91"
   },
   "outputs": [],
   "source": [
    "# Gathering vectors of label names using idx2label\n",
    "true_label_texts, pred_label_texts = [], []\n",
    "for vals in true_label_idxs:\n",
    "  if vals:\n",
    "    true_label_texts.append([idx2label[val] for val in vals])\n",
    "  else:\n",
    "    true_label_texts.append(vals)\n",
    "\n",
    "for vals in pred_label_idxs:\n",
    "  if vals:\n",
    "    pred_label_texts.append([idx2label[val] for val in vals])\n",
    "  else:\n",
    "    pred_label_texts.append(vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "id": "5HaqV6pn_HCG"
   },
   "outputs": [],
   "source": [
    "# Decoding input ids to ocr text\n",
    "ocr_texts = [tokenizer.decode(text,skip_special_tokens=True,clean_up_tokenization_spaces=False) for text in tokenized_texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "R7kk0Mgl1L-T",
    "outputId": "1d286981-2b54-43af-b02b-9512f0113ce0"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment_text</th>\n",
       "      <th>true_labels</th>\n",
       "      <th>pred_labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>['or this what kind of reputation are these pi...</td>\n",
       "      <td>[Angry, Disgust, Fear, Neutral]</td>\n",
       "      <td>[Surprise, Neutral]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>['he is not telling all he knows , do you thin...</td>\n",
       "      <td>[Angry, Fear, Neutral]</td>\n",
       "      <td>[Neutral]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>['you big stupid why do not you watch where yo...</td>\n",
       "      <td>[Angry, Neutral]</td>\n",
       "      <td>[Angry, Neutral]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>['fight it out with him it is the gallows if h...</td>\n",
       "      <td>[Angry, Disgust, Fear, Surprise, Neutral]</td>\n",
       "      <td>[Angry, Neutral]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>['this way to the roof   .', 'the fleeing boxe...</td>\n",
       "      <td>[Fear, Happy, Neutral]</td>\n",
       "      <td>[Angry, Neutral]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        comment_text  \\\n",
       "0  ['or this what kind of reputation are these pi...   \n",
       "1  ['he is not telling all he knows , do you thin...   \n",
       "2  ['you big stupid why do not you watch where yo...   \n",
       "3  ['fight it out with him it is the gallows if h...   \n",
       "4  ['this way to the roof   .', 'the fleeing boxe...   \n",
       "\n",
       "                                 true_labels          pred_labels  \n",
       "0            [Angry, Disgust, Fear, Neutral]  [Surprise, Neutral]  \n",
       "1                     [Angry, Fear, Neutral]            [Neutral]  \n",
       "2                           [Angry, Neutral]     [Angry, Neutral]  \n",
       "3  [Angry, Disgust, Fear, Surprise, Neutral]     [Angry, Neutral]  \n",
       "4                     [Fear, Happy, Neutral]     [Angry, Neutral]  "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Converting lists to df\n",
    "comparisons_df = pd.DataFrame({'ocr_text': ocr_texts, 'true_labels': true_label_texts, 'pred_labels':pred_label_texts})\n",
    "# comparisons_df.to_csv('comparisons.csv')\n",
    "comparisons_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PWFd18u3zlF8"
   },
   "source": [
    "## Bonus - Optimizing threshold value for macro ROC score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c6mDy1lw0S4y"
   },
   "source": [
    "Doing this may result in a trade offs between precision, flat accuracy and micro F1 accuracy. You may tune the threshold however you want."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PHlhb2lvar8V",
    "outputId": "d43381d9-db15-4415-89bb-f5a527911097"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Threshold:  0.4\n",
      "Test roc_auc Accuracy:  0.5672297107264808\n",
      "Test Flat Accuracy:  0.05358615004122012 \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Angry       0.52      0.45      0.48       474\n",
      "     Disgust       0.50      0.53      0.51       450\n",
      "        Fear       0.58      0.34      0.42       444\n",
      "       Happy       0.55      0.72      0.63       516\n",
      "         Sad       0.31      0.02      0.04       206\n",
      "    Surprise       0.37      0.47      0.41       412\n",
      "     Neutral       0.68      0.90      0.78       797\n",
      "      Others       0.67      0.03      0.05        75\n",
      "\n",
      "   micro avg       0.55      0.56      0.56      3374\n",
      "   macro avg       0.52      0.43      0.42      3374\n",
      "weighted avg       0.54      0.56      0.52      3374\n",
      " samples avg       0.57      0.59      0.55      3374\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shwetkm/anaconda3/envs/ml/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Calculate Accuracy - maximize roc_auc score by tuning threshold values. First with 'macro_thresholds' on the order of e^-1 then with 'micro_thresholds' on the order of e^-2\n",
    "\n",
    "macro_thresholds = np.array(range(1,10))/10\n",
    "\n",
    "roc_auc_results, flat_acc_results = [], []\n",
    "for th in macro_thresholds:\n",
    "  pred_bools = [pl>th for pl in pred_labels]\n",
    "  test_roc_auc_accuracy = roc_auc_score(true_bools,pred_bools,average='macro')\n",
    "  test_flat_accuracy = accuracy_score(true_bools, pred_bools)\n",
    "  roc_auc_results.append(test_roc_auc_accuracy)\n",
    "  flat_acc_results.append(test_flat_accuracy)\n",
    "\n",
    "best_macro_th = macro_thresholds[np.argmax(roc_auc_results)] #best macro threshold value\n",
    "\n",
    "micro_thresholds = (np.array(range(10))/100)+best_macro_th #calculating micro threshold values\n",
    "\n",
    "roc_auc_results, flat_acc_results = [], []\n",
    "for th in micro_thresholds:\n",
    "  pred_bools = [pl>th for pl in pred_labels]\n",
    "  test_roc_auc_accuracy = roc_auc_score(true_bools,pred_bools,average='macro')\n",
    "  test_flat_accuracy = accuracy_score(true_bools, pred_bools)\n",
    "  roc_auc_results.append(test_roc_auc_accuracy)\n",
    "  flat_acc_results.append(test_flat_accuracy)\n",
    "\n",
    "best_roc_auc_idx = np.argmax(roc_auc_results) #best threshold value\n",
    "\n",
    "# Printing and saving classification report\n",
    "print('Best Threshold: ', micro_thresholds[best_roc_auc_idx])\n",
    "print('Test roc_auc Accuracy: ', roc_auc_results[best_roc_auc_idx])\n",
    "print('Test Flat Accuracy: ', flat_acc_results[best_roc_auc_idx], '\\n')\n",
    "\n",
    "best_pred_bools = [pl>micro_thresholds[best_roc_auc_idx] for pl in pred_labels]\n",
    "clf_report_optimized = classification_report(true_bools,best_pred_bools, target_names=label_cols)\n",
    "pickle.dump(clf_report_optimized, open('classification_report_optimized.txt','wb'))\n",
    "print(clf_report_optimized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oBg6UCYAYtIe",
    "outputId": "16931d0a-f6b3-46c6-f0fc-f01f02826913"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5672297107264808"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(true_bools, best_pred_bools,average='macro')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "emotion_text_transformers.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
